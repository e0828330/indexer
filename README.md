Text Indexer & Similarity Retrieval

1. Usage

TBD

2. Implementation details

The indexing process gets as input a directory that contains the document
collection, a Boolean that indicates whether stemming should be used or not 
and the frequency threshold.

The indexer itself works similar to the MapReduce approach described in the book
and the slides. Instead of assigning tasks to nodes it uses threads on a single 
machine. The idea behind that was to use the multiple CPU cores found on todays
machines to speed up the indexing process.

A thread pool is used to lower the overhead of spawning new threads.

The parser threads parse one document each. The number of running threads is lim
ited to the number of available Processors. The directory traversal, which is done
by the main thread generally is faster then the the parsers but this isn't a 
problem be cause the threads will just get queued and run once one of the currently
 running parsers is finished.

Once the parsers are done parsing the document the indexer will run the inverter
threads using the same techniques as the parser. Each inverter gets a term and a 
list of documents that contain said term. Those lists have been generated by the
parsers in the previous step.
The inverters create the posting lists, calculate the term frequencies (and 
discard documents whose term frequencies are outside of the thresholds).
Afterwards the tf.idf weights are calculatedfor each posting.

Once the inverters are done we have an inverted index (that is currently
completely in memory due to its small size). 

The index is then used to create a sparse gzip compressed ARFF file. The ARFF 
file writing has been implemented by hand because WEKA turned out to be 
significantly slower at doing this task. In addition to the terms the ARFF
contains the document class, document id and a flag indicating whether stemming
has been used or not to create the ARFF file. The later ensures that stemming
will be used for the search when stemming has been used to create the index.

For the search step the document vectors and the index are rebuild from the ARFF
file. Sorting of the posting lists is done using multiple threads to speed things
up. 

The search itself uses the FASTCOSINESOURCE algorithm from the book (using the 
td.idf weight) to find the most relevant documents.

We have just used the whole text of the topic files as input for the search, but
we do provide an interface for searching using any text (see usage section for
 details).

